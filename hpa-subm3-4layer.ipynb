{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"hpa-subm3-4layer.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"a6WJTgGI0F4K","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","#import numpy as np # linear algebra\n","#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","#import os\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","#    for filename in filenames:\n","#        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IZCIOL2C0F4T","colab_type":"text"},"source":["Essentially a simplified, modified version of tinkertytonk project - so credit to him"]},{"cell_type":"markdown","metadata":{"id":"cC9NQY9a0Wrn","colab_type":"text"},"source":["Attach data and make sure GPU is enabled before running this nb"]},{"cell_type":"code","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"ByfbYtkC0F4W","colab_type":"code","colab":{}},"source":["!pip install kaggle --upgrade -q"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"sJxoRXTu0F4b","colab_type":"code","colab":{}},"source":["import os\n","import gc\n","import numpy as np\n","# import jovian\n","import cv2\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","from fastai import *\n","from fastai.vision import *\n","from fastai.metrics import accuracy, error_rate\n","from fastai.callbacks import *\n","\n","from PIL import Image\n","from tqdm.notebook import tqdm \n","from pathlib import Path"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P1bzxkIm0F4g","colab_type":"text"},"source":["Setup Kaggle API Key"]},{"cell_type":"code","metadata":{"trusted":true,"id":"UyJvW8qF0F4i","colab_type":"code","colab":{}},"source":["os.environ['KAGGLE_USERNAME']=\"skr1125\"\n","os.environ['KAGGLE_KEY']=\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"-_vpIKtR0F4n","colab_type":"code","colab":{}},"source":["!pwd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"qCtfsRWL0F4s","colab_type":"code","colab":{}},"source":["!ls ../input"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"4-TusX6e0F4z","colab_type":"code","colab":{}},"source":["# setting up paths for use in the notebook\n","PATH = '../input/human-protein-atlas-image-classification/'\n","TRAIN = '../input/human-protein-atlas-image-classification/train/'\n","TEST =  '../input/human-protein-atlas-image-classification/test/'\n","LABELS = '../input/human-protein-atlas-image-classification/train.csv'\n","path_working = Path('/kaggle/working')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"eYKwqaF70F43","colab_type":"code","colab":{}},"source":["channels4 = ['_yellow', '_red', '_green_', '_blue']\n","channels3 = ['_red', '_green', '_blue']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"w-VKSeL30F49","colab_type":"code","colab":{}},"source":["index_class_dict = {\n","0:  'Nucleoplasm',\n","1:  'Nuclear membrane',\n","2:  'Nucleoli',   \n","3:  'Nucleoli fibrillar center',\n","4:  'Nuclear speckles',\n","5:  'Nuclear bodies',\n","6:  'Endoplasmic reticulum',   \n","7:  'Golgi apparatus',\n","8:  'Peroxisomes',\n","9:  'Endosomes',\n","10:  'Lysosomes',\n","11:  'Intermediate filaments',\n","12:  'Actin filaments',\n","13:  'Focal adhesion sites',   \n","14:  'Microtubules',\n","15:  'Microtubule ends',  \n","16:  'Cytokinetic bridge',   \n","17:  'Mitotic spindle',\n","18:  'Microtubule organizing center',  \n","19:  'Centrosome',\n","20:  'Lipid droplets',\n","21:  'Plasma membrane',   \n","22:  'Cell junctions', \n","23:  'Mitochondria',\n","24:  'Aggresome',\n","25:  'Cytosol',\n","26:  'Cytoplasmic bodies',   \n","27:  'Rods & rings' }"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OJ-W9Xn60F5E","colab_type":"text"},"source":["The following two cells are really NOT needed for the process of visualizing or conducting the training. Just an illustration to show the file and process it into a one hot vector of structures present in the training images."]},{"cell_type":"code","metadata":{"trusted":true,"id":"SSaqKEcj0F5G","colab_type":"code","colab":{}},"source":["# Read the training data so that the cell id and the structures they contain (as strings) can be seen in the Target field\n","train_df = pd.read_csv(LABELS) # see LABELS definition above\n","train_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"v7WLUsfX0F5L","colab_type":"code","colab":{}},"source":["# next convert the whole thing into a one hot vector coding as well \n","for i in range(28):\n","    train_df[f'{index_class_dict[i]}'] = train_df['Target'].map(lambda x:1 if str(i) in x.strip().split() else 0)\n","train_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dt0H7Sn80F5V","colab_type":"text"},"source":["The cells below need to be repeated for the 4 channel case. I am trying this first for a simple 3 channel model"]},{"cell_type":"code","metadata":{"trusted":true,"id":"btMYfXlB0F5W","colab_type":"code","colab":{}},"source":["# Suppose we only use the rgb values provided initially and IGNORE the y values, so only 3 channels \n","# We will try 4 channels after that - remember to initialize y value with avg of other 3 NOT zeros\n","# import Fastai vision to get their Image class\n","from fastai.vision.image import *\n","\n","# taken from : https://github.com/wdhorton/protein-atlas-fastai/blob/master/utils.py\n","# discussion : https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/71039\n","# adapted from https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb\n","def open_3_channel(fname):\n","    fname = str(fname)\n","    # strip extension before adding color\n","    if fname.endswith('.png'):\n","        fname = fname[:-4]\n","    # SKR: colors below changed to only be 3 colors red, green, blue \n","    # SKR: IGNORING YELLOW for now\n","    #colors = ['red','green','blue','yellow']\n","    colors = ['red', 'green', 'blue']\n","    flags = cv2.IMREAD_GRAYSCALE\n","    \n","    img = [cv2.imread(fname+'_'+color+'.png', flags).astype(np.float32)/255\n","           for color in colors]\n","    \n","    # convert from a [512,512,4] tensor to a [4,512,512] tensor\n","    # convert from a [512, 512, 3] tensor to a [3, 512, 512] tensor\n","    x = np.stack(img, axis=-1)    \n","    \n","    # create a Fastai image from the tensor\n","    return Image(pil2tensor(x, np.float32).float())\n","\n","def open_4_channel(fname):\n","    fname = str(fname)\n","    # strip extension before adding color\n","    if fname.endswith('.png'):\n","        fname = fname[:-4]\n","    colors = ['red','green','blue','yellow']\n","    flags = cv2.IMREAD_GRAYSCALE\n","    \n","    img = [cv2.imread(fname+'_'+color+'.png', flags).astype(np.float32)/255\n","           for color in colors]\n","\n","    x = np.stack(img, axis=-1)    \n","    \n","    # create a Fastai image from the tensor\n","    return Image(pil2tensor(x, np.float32).float())\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V1jPARxU0F5a","colab_type":"text"},"source":["Create the DataBunch. Here another approach could be to size the images to be 224 x 224 above and train the model first \n","THEN train the model on 512 x 512 images and use that model to predict. "]},{"cell_type":"code","metadata":{"trusted":true,"id":"UdEYCoIe0F5b","colab_type":"code","colab":{}},"source":["bs=32\n","size=512"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"RppazeUc0F5f","colab_type":"code","colab":{}},"source":["# read submission file to get the names of test images\n","test_df = pd.read_csv(PATH + 'sample_submission.csv')\n","test_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"L6Eiut1H0F5k","colab_type":"code","colab":{}},"source":["np.random.seed(230)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ESSYoMBT0F5p","colab_type":"code","colab":{}},"source":["PATH"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"PFZRKUuw0F5s","colab_type":"code","colab":{}},"source":["test = ImageList.from_df(test_df, PATH, folder='test', suffix='.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"IbszLPlJ0F5w","colab_type":"code","colab":{}},"source":["src = (ImageList.from_df(train_df, PATH, folder='train', suffix='.png')\n","                .split_by_rand_pct(0.2)\n","                .label_from_df(cols='Target', label_delim=' ')\n","                .add_test(test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"W1usS_t_0F50","colab_type":"code","colab":{}},"source":["src.train.x.create_func = open_4_channel\n","src.train.x.open = open_4_channel\n","\n","src.valid.x.create_func = open_4_channel\n","src.valid.x.open = open_4_channel"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ypSoQV5D0F7C","colab_type":"code","colab":{}},"source":["src.test.x.create_func = open_4_channel\n","src.test.x.open = open_4_channel"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"gltYl-p80F7G","colab_type":"code","colab":{}},"source":["# 4 channel protein stats - going to only 3 channel stats\n","protein_stats = ([0.08069, 0.05258, 0.05487, 0.08282], [0.13704, 0.10145, 0.15313, 0.13814])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"_pkMvlRh0F7K","colab_type":"code","colab":{}},"source":["# create databunch after using bs and normalizing using protein stats\n","data = src.databunch(bs=bs).normalize(protein_stats)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"3xDQ3JdW0F7O","colab_type":"code","colab":{}},"source":["data.show_batch(rows=3, figsize=(12,9))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"0yuVnaqf0F7S","colab_type":"code","colab":{}},"source":["data.c"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ersatKpu1MCN","colab_type":"text"},"source":["Need to modify the model to be 4 channel. So following this kaggle kernel\n","https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb\n","and implementing a 4 channel modification of Resnet34 but loading the weights\n","for the 3 channels from pretrained model and creating starting point for weights of Y channel to be initialized with values from other channels (could try different variants of this if so inclined)."]},{"cell_type":"code","metadata":{"id":"zIoFxLKm12wu","colab_type":"code","trusted":true,"colab":{}},"source":["class Resnet34_4(nn.Module):\n","    def __init__(self, pre=True):\n","        super().__init__()\n","        encoder = models.resnet34(pretrained=pre)\n","        \n","        self.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        if(pre):\n","            w = encoder.conv1.weight\n","            self.conv1.weight = nn.Parameter(torch.cat((w,\n","                                    0.5*(w[:,:1,:,:]+w[:,2:,:,:])),dim=1))\n","        \n","        self.bn1 = encoder.bn1\n","        self.relu = nn.ReLU(inplace=True) \n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer0 = nn.Sequential(self.conv1,self.relu,self.bn1,self.maxpool)\n","        self.layer1 = encoder.layer1\n","        self.layer2 = encoder.layer2\n","        self.layer3 = encoder.layer3\n","        self.layer4 = encoder.layer4\n","        #the head will be added automatically by fast.ai\n","        \n","    def forward(self, x):\n","        x = self.layer0(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        \n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"WvCOfAom0F7W","colab_type":"code","colab":{}},"source":["# arch = models.resnet34\n","arch = Resnet34_4"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pu91lIG00F7Z","colab_type":"text"},"source":["This should be modified to be different metrics as per competition spec"]},{"cell_type":"code","metadata":{"trusted":true,"id":"FPkqyj-i0F7a","colab_type":"code","colab":{}},"source":["acc_02 = partial(accuracy_thresh, thresh=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"VeqrFlDi0F7f","colab_type":"code","colab":{}},"source":["f_score = partial(fbeta, thresh=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"aSk-bTFm0F7i","colab_type":"code","colab":{}},"source":["learn = cnn_learner(data, arch, metrics=[acc_02, f_score])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jUAsk9uz0F7l","colab_type":"text"},"source":["Need to set learn.model_dir attribute in Learner to a full libpath path that is writable and so "]},{"cell_type":"code","metadata":{"trusted":true,"id":"VwfbGeY80F7m","colab_type":"code","colab":{}},"source":["learn.model_dir = path_working "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"NiUZO-Fa0F7q","colab_type":"code","colab":{}},"source":["path_working"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"nuRydeYX0F7v","colab_type":"code","colab":{}},"source":["learn.model_dir = path_working"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"R_MKnJyw0F7z","colab_type":"code","colab":{}},"source":["learn.model_dir"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"QFT4r56B0F72","colab_type":"code","colab":{}},"source":["learn.lr_find()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"JLY5bpwG0F76","colab_type":"code","colab":{}},"source":["learn.recorder.plot()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"q1USH3zj0F79","colab_type":"code","colab":{}},"source":["lr = 2e-2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"PIxdGS520F8C","colab_type":"code","colab":{}},"source":["learn.fit_one_cycle(10, slice(lr))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"OzrPv-Ik0F8F","colab_type":"code","colab":{}},"source":["learn.save('stage1-rn34-4ch')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"qbhJaMPO0F8I","colab_type":"code","colab":{}},"source":["learn.unfreeze()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"cPQD1JNy0F8Q","colab_type":"code","colab":{}},"source":["learn.lr_find()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"NTZ2aFoo0F8V","colab_type":"code","colab":{}},"source":["learn.recorder.plot()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"mxXuyboz0F8Z","colab_type":"code","colab":{}},"source":["# training longer to better train y weights\n","learn.fit_one_cycle(10, slice(1e-5, lr/5))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"lRviCvPM0F8c","colab_type":"code","colab":{}},"source":["learn.save('stage2-rn34-4ch')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"n8HKx3JP0F8f","colab_type":"code","colab":{}},"source":["preds, _ = learn.get_preds(DatasetType.Test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"NPxjTLmT0F8l","colab_type":"code","colab":{}},"source":["type(preds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"8z3Rk4Kt0F8p","colab_type":"code","colab":{}},"source":["preds.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"JkgPueyy0F8s","colab_type":"code","colab":{}},"source":["type(learn.data.classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"d-IKdcpm0F8u","colab_type":"code","colab":{}},"source":["len(learn.data.classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"FVBkrSgz0F8x","colab_type":"code","colab":{}},"source":["thresh = 0.2\n","labelled_preds = [' '.join([learn.data.classes[i] for i,p in enumerate(pred) if p > thresh]) for pred in preds]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"z4da7Wtt0F8z","colab_type":"code","colab":{}},"source":["len(labelled_preds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"0AxnxNH90F83","colab_type":"code","colab":{}},"source":["labelled_preds[:5]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"oByLikYf0F86","colab_type":"code","colab":{}},"source":["learn.data.test_ds.items[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"chjCJPBk0F8-","colab_type":"code","colab":{}},"source":["Path(learn.data.test_ds.items[0]).stem"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"74pDZ37T0F9A","colab_type":"code","colab":{}},"source":["# converting image path strings to the file name only with no extension\n","fnames = [Path(f).stem for f in learn.data.test_ds.items]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"aYQDBdSl0F9C","colab_type":"code","colab":{}},"source":["sample_list = list(test_df.Id)\n","# sample_list[:5]\n","pred_dict = dict((key, value) for (key, value) in zip(fnames, labelled_preds))\n","pred_list_cor = [pred_dict[id] for id in sample_list]\n","df = pd.DataFrame({'ID':sample_list, 'Predicted':pred_list_cor})\n","df.to_csv('protein_classification.csv', header=True, index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"yxbZx9gK0F9F","colab_type":"code","colab":{}},"source":["df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"_7yvxwUy0F9H","colab_type":"code","colab":{}},"source":["# Submit\n","!kaggle competitions submit -c human-protein-atlas-image-classification -f protein_classification.csv -m \"Message\"\n","\n","# View results\n","!kaggle competitions submissions -c human-protein-atlas-image-classification > results.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"kMwRPyVp0F9K","colab_type":"code","colab":{}},"source":["!ls results.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"XTKqaa820F9M","colab_type":"code","colab":{}},"source":["!more results.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"xzaXjZoa0F9R","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"WYJoZLgJ0F9T","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"uqbDGHwG0F9Y","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"xEHyArlr0F9a","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"sxWqCcIv0F9e","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}